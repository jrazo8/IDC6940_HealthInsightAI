---
title: "Diagnosing Diseases using kNN"
subtitle: "An application of kNN to diagnose Diabetes"
author: "Jacqueline Razo (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  revealjs:
    citeproc: true
    css: styles.css
course: Capstone Projects in Data Science
bibliography: references.bib 
#always_allow_html: true 
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction  {.smaller}

- The k-Nearest-Neighbors (kNN) is an algorithm that can be used in a variety of fields to classify or predict data [@ali2020diabetes]

- It's a simple algorithm that classifies data based on how similar a datapoint is to a class of datapoints. [@zhang2016introduction]

- One of the benefits of using this algorithmic model is how simple it is to use and the fact it’s non-parametric which means it fits a wide variety of datasets.

- One drawback from using this model is that it does have a higher computational cost than other models which means that it doesn’t perform as well or fast on big data [@deng2016efficient]

- In this project we focused on the methodology and application of classification kNN models in the field of healthcare or public health to predict or screen for diabetes. 


## Methodology Overview {.smaller}


- The kNN algorithm is a nonparametric supervised learning algorithm that can be used for classification or regression problems. [@syriopoulos2023k]

The classification process has three distinct steps:

::: {.scroll-box style="height: 425px; overflow-y: auto; border:1px solid #ccc; padding: 10px;"}


**1. Distance Calculation **

$$
d = \sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2}
$$
[@kataria2013review]
```{r}
library(ggplot2)

#Add points (X1, Y1) and (X2, Y2)
X1 <- 10; Y1 <- 12
X2 <- 14; Y2 <- 16

#creates a plot
plot(c(X1, X2), c(Y1, Y2), type = "n", xlab = "X-axis", ylab = "Y-axis", main = "Figure 2: Euclidean Distance",xlim = c(X1 - 4, X2 + 4), ylim = c(Y1 - 4, Y2 + 4))

#Plot first point
points(X1, Y1, col = "red", pch = 16, cex = 2) 

#Plot second point
points(X2, Y2, col = "blue", pch = 16, cex = 2)

#Add horizontal line
segments(X1, Y1, X2, Y1, col = "green", lwd = 2)

#Add vertical line 
segments(X2, Y1, X2, Y2, col = "green", lwd = 2)

#Add hypotenuse line
segments(X1, Y1, X2, Y2, col = "purple", lwd = 2, lty = 2)

#Add labels
text(X1, Y1, labels = paste("(X1, Y1)\n(", X1, ",", Y1, ")"), pos = 2, col = "red", cex = 0.7) 
text(X2, Y2, labels = paste("(X2, Y2)\n(", X2, ",", Y2, ")"), pos = 4, col = "blue", cex = 0.7)
text((X1 + X2) / 2 -2, (Y1 + Y2) / 2 + 3, "Euclidean Distance (d)", col = "purple", font = 2, cex = 1.2)
arrows((X1 + X2) / 2, (Y1 + Y2) / 2 + 2,(X1 + X2) / 2, (Y1 + Y2) / 2,col = "purple", lwd = 2, length = 0.1)

#insert formula

text(mean(c(X1, X2)), mean(c(Y1, Y2)) - 5, labels = expression(d == sqrt((14 - 10)^2 + (16 - 12)^2)), col = "black", cex = 0.9, font = 1)




```

**2. Neighbor Selection** 

      K=5  vs K=15
    
    
**3. Classification decision based on majority voting**
    
      Majority wins 
:::

## Methodology Visualization {.smaller}

- Figure 1 illustrates this methodology with two distinct classes of hearts and circles. 

![Figure 1](images/kNN_picture.png){width="500" height="600"}


## Assumptions {.smaller}

- The kNN algorithm assumes similar datapoints will be in close proximity to each other and be neighbors [@zhang2016introduction].

- It also assumes that data points with similar features belong to the same class.
[@boateng2020basic]

## Pre-processing Data {.smaller}
- **Handle missing values**: We must remove the missing values by either inputting them or dropping them to prevent them from skewing the results.
- **Make all values numeric**: All categorical values must be encoded using either one-hot encoding or label encoding.
- **Normalize or Standardize the features**: We must use min-max scaler or the standard scaler to make sure we reduce bias. 
- **Reduce dimensionality**: We can use Principal Component Analysis to reduce the
    number of features but keep the variance.
- **Remove correlated features**: The kNN works best when there aren't
    too many features, so we can use a correlation matrix to see which
    features we can drop. 
- **Fix class imbalance**: Synthetic Minority Over-sampling Technique(SMOTE) can be used to handle class imbalances that can cause biases. 

## Hyperparameter Tuning {.smaller}

In order to increase the accuracy of the model there are a few
parameters that we can adjust.

**1.  Find the optimal k parameter:** We can use gridsearch to find the best
    parameter k.
  
**2.  Change the distance metric:** The kNN uses the euclidean distance by
    default but we can use the Manhattan distance, the Minkowski
    distance or another distance.
  
**3.  Weights:** The kNN defaults to a "uniform" weight where it gives the
    same weight to all the distances but it can be adjusted to
    "distance" so that the closest neighbors have more weight.

## Dataset Overview {.smaller}
- We explored the [CDC Diabetes Health
Indicators](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators.) dataset, sourced from the UC Irvine Machine Learning Repository. 

- The dataset consists of 253,680 survey responses and contains 21 feature variables and 1 binary target variable named **Diabetes_binary**

- **Diabetes_binary**: 0= No Diabetes, 1= Diabetes

- **Binary Variables**: HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, DiffWalk, Sex.

- **Ordinal Variables**: GenHlth, MentHlth, PhysHlth, Age, Education, Income

- **Continuous Variables**: BMI


## Data Exploration and Visualization - Outliers {.smaller}

Figure 5 shows us outliers in the data that can skew our results 

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from ucimlrepo import fetch_ucirepo

# Import dataset
cdc_diabetes_health_indicators = fetch_ucirepo(id=891)

# Combine features and targets into one DataFrame
cdc_data_df = pd.concat([
    cdc_diabetes_health_indicators.data.features,
    cdc_diabetes_health_indicators.data.targets
], axis=1)

# Exclude binary columns
ord_variables = ['GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income', 'BMI']

# Create boxplot
plt.figure(figsize=(12, 6))
sns.boxplot(data=cdc_data_df[ord_variables], orient="h", palette="Set2")
plt.title("Figure 5: Boxplot showing Outliers for Ordinal and Continuous Variables")
plt.xlabel("Value")
plt.tight_layout()
plt.show()

```
## Data Exploration and Visualization - Class imbalance {.smaller}

Figure 6 shows the class imbalance present in the data

```{python}

import pandas as pd
import matplotlib.pyplot as plt

# Filter binary columns 
binary_cols = [col for col in cdc_data_df.columns 
               if set(cdc_data_df[col].dropna().unique()).issubset({0, 1})]

# Count 0s and 1s
binary_counts = pd.DataFrame({
    '0': (cdc_data_df[binary_cols] == 0).sum(),
    '1': (cdc_data_df[binary_cols] == 1).sum()
})

# Plot
binary_counts.plot(kind='barh', stacked=True, figsize=(10, 8), colormap='Set2')
plt.title("Figure 6: Binary Feature Distribution of 0 and 1")
plt.xlabel("Count")
plt.ylabel("Feature")
plt.legend(title="Class")
plt.tight_layout()
plt.show()

```


## Data Exploration and Visualization - Key Findings {.smaller}

- There are no missing values, meaning no imputation is needed.

- We have some duplicate values that need to be removed.

- There is a class imbalance with the majority of cases not having diabetes.

## Building the Models {.smaller}

- There was no missing data so we didn't have to remove or impute any values but we did clean the data by dropping duplicate values. 
- We kept the ordinal variables the same as they have meaningful natural order that will provide the kNN with meaningful distances.
- The data was divided into testing and training data. We used a **test_size=0.2** to use 80% of the data for training the kNN and 20% of the data for testing.
- The features were standardized so that BMI and age could be on the same scale as the other features.
- Gridsearch was used to find the optimal parameters for hyperparameter tuning
- We experimented with different decision thresholds due to the imbalanced dataset. 

## Modeling and Results - Model Creation {.smaller}

We chose to create four classification kNN models to illustrate the
methodology.

```{r}
#Load gt package
library(gt)

#Create dataframe
model_sum <- data.frame(
  Model = c("Model 1", "Model 2", "Model 3", "Model 4" ),
  k = c(5, 15, 15, 15), Weights = c("'uniform'", "'uniform'", "'distance'","'uniform'"),Distance = rep("Euclidean", 4),SMOTE = c("No", "No", "Yes","Yes"), 'Decision_Threshold' = c(0.5, 0.5, 0.5,0.2))

# Create Table 
model_sum %>%
  gt() %>%tab_header(title = md("**Table 4: Model Summary**")
  ) %>%cols_label(Model = "Model Name",k = "k value",Weights = "Weights", Distance = "Distance",SMOTE = "SMOTE",`Decision_Threshold` = "Decision Threshold") %>%cols_align(align = "center",columns = everything()) %>%tab_options(table.border.top.width = px(2),table.border.bottom.width = px(2),heading.align = "left")

```

```{python, echo=FALSE, include=FALSE}
# Pre-processing for Model 1 and Model 2

# Import libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from ucimlrepo import fetch_ucirepo 

# Load the dataset  
cdc_diabetes_health_indicators = fetch_ucirepo(id=891) 

# Create dataframe by combining features and targets
cdc_data_df = pd.concat(
    [cdc_diabetes_health_indicators.data.features, 
     cdc_diabetes_health_indicators.data.targets],
    axis=1
)

# Drop duplicate rows
cdc_data_df.drop_duplicates(inplace=True)

# Separate features and target 
X = cdc_data_df.drop(columns="Diabetes_binary")
y = cdc_data_df["Diabetes_binary"]

# Split training and testing data with an 80/20 mix
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

```

```{python, echo=FALSE, include=FALSE}
#Extra pre-processing step for Model 3 ONLY
from imblearn.over_sampling import SMOTE

# Apply SMOTE to training data to use for Model 3
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

```

```{python, echo=FALSE, include=FALSE}

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix 

# Model 1: 
knn_model_1 = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')
knn_model_1.fit(X_train_scaled, y_train)
y_pred1 = knn_model_1.predict(X_test_scaled)
print(classification_report(y_test, y_pred1))
print(confusion_matrix(y_test, y_pred1))

```

```{python, echo=FALSE, include=FALSE}

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix

# Model 2: 
knn_model_2 = KNeighborsClassifier(n_neighbors=15, weights='uniform', metric='euclidean')
knn_model_2.fit(X_train_scaled, y_train)
y_pred2 = knn_model_2.predict(X_test_scaled)
print(classification_report(y_test, y_pred2))
print(confusion_matrix(y_test, y_pred2))

```

```{python, echo=FALSE, include=FALSE}

# Model 3:
knn_model_3 = KNeighborsClassifier(n_neighbors=15, weights='distance', metric='euclidean')
knn_model_3.fit(X_train_smote, y_train_smote)
y_pred_3 = knn_model_3.predict(X_test_scaled)
print(classification_report(y_test, y_pred_3))
print(confusion_matrix(y_test, y_pred_3))

```


```{python, echo=FALSE, include=FALSE}

#Model 4
knn_model_4 = KNeighborsClassifier(n_neighbors=15, weights='uniform', metric='euclidean')
knn_model_4.fit(X_train_smote, y_train_smote)

# Adjust decision threshold
y_prob_4 = knn_model_4.predict_proba(X_test_scaled)[:, 1]
threshold = 0.2
y_pred_4 = (y_prob_4 >= threshold).astype(int)
print(classification_report(y_test, y_pred_4))
print(confusion_matrix(y_test, y_pred_4))

```

## Modeling and Results- Evaluating the models {.smaller}

The table below shows the summary of the four models.

```{python}
# import libraries
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score

# Create dataframe 
results = pd.DataFrame({
    'Model': ['Model 1', 'Model 2', 'Model 3', 'Model 4'],'k': [5, 15, 15, 15],
    'Weight': ['Uniform', 'Uniform', 'Distance', 'Uniform' ],
    'SMOTE': ['No', 'No', 'Yes', 'Yes'],
    'Decision Threshold': ['0.5', '0.5', '0.5', '0.2'],
    'Accuracy': [
        accuracy_score(y_test, y_pred1),
        accuracy_score(y_test, y_pred2),
        accuracy_score(y_test, y_pred_3),
        accuracy_score(y_test, y_pred_4)
    ],
    'F1 Score': [
        f1_score(y_test, y_pred1),
        f1_score(y_test, y_pred2),
        f1_score(y_test, y_pred_3),
        f1_score(y_test, y_pred_4)
    ],
    'Precision': [
        precision_score(y_test, y_pred1),
        precision_score(y_test, y_pred2),
        precision_score(y_test, y_pred_3),
        precision_score(y_test, y_pred_4)
    ],
    'Recall': [
        recall_score(y_test, y_pred1),
        recall_score(y_test, y_pred2),
        recall_score(y_test, y_pred_3),
        recall_score(y_test, y_pred_4)
    ],
    'ROC AUC': [
        roc_auc_score(y_test, knn_model_1.predict_proba(X_test_scaled)[:, 1]),
        roc_auc_score(y_test, knn_model_2.predict_proba(X_test_scaled)[:, 1]),
        roc_auc_score(y_test, knn_model_3.predict_proba(X_test_scaled)[:, 1]),
        roc_auc_score(y_test, knn_model_4.predict_proba(X_test_scaled)[:, 1])
        
    ]
})

# Design the table 
results.style \
    .set_caption("KNN Model Performance Summary") \
    .format({
        "Accuracy": "{:.2%}",
        "F1 Score": "{:.2%}",
        "Precision": "{:.2%}",
        "Recall": "{:.2%}",
        "ROC AUC": "{:.2f}"
    }) \
    .set_properties(**{'text-align': 'center'}) \
    .set_table_styles([
        {'selector': 'caption', 'props': [('caption-side', 'top'), ('font-weight', 'bold'), ('font-size', '16px')]},
        {'selector': 'th', 'props': [('background-color', '#f2f2f2'), ('font-size', '14px')]}
    ])


```


## Results {.smaller}

- Model 2 has the highest accuracy at 84.56% but this accuracy score is high because it is good at detecting the non-diabetic cases which are the majority of cases.

- Model 2 also has the highest ROC AUC score of 0.77 which means it’s the best model at separating different classes; however, the recall is 14.56% so it's only classifying 14.56% of the actual positive diabetic cases. 

- Model 3 has an accuracy of 69.77% and a much higher recall of 69.58%. Model 3 is able to correctly classify about 70% of the positive diabetic cases.

- Model 4 has the best recall with the ability to classify 91.62% of the positive diabetic cases but the overall accuracy is at 47.52% so it is classifying non-diabetic cases as diabetic. 

## Conclusion {.smaller}

- kNN is a promising algorithmic model that can be further improved to classify or screen for diabetes. 

- Model 3 showed potential with classifying diabetic cases but would need to be further improved by being trained with data that shows more diabetic cases if it's going to be used in a healthcare setting. 

- Model 4 showed high potential for screening for diabetes and would be useful in a public health setting where people are classified as high risk for diabetes based on their self reported helath indicators and referred for lifestyle education and biochemical testing. 

## References {.smaller}

